# Load packages
library(ggplot2)
library(haven)
library(dplyr)


###############################
# CPN on real data            #
###############################

find_Kmax <- function(lambda, epsilon = 1e-6) {
  Kmax <- 0
  tail_prob <- 1 - ppois(Kmax, lambda)
  
  while (tail_prob > epsilon) {
    Kmax <- Kmax + 1
    tail_prob <- 1 - ppois(Kmax, lambda)
  }
  
  return(Kmax)
}


# Negative log-likelihood function for Compound Poisson-Normal distribution
cpn_neg_log_likelihood <- function(params, data) {
  lambda <-  params[1]  # Poisson rate (expected number of normal components per observation)
  mu <-   params[2]     # Mean of each normal component
  sigma <-   params[3]  # Standard deviation of each normal component
  
  if (lambda <= 0 || sigma <= 0) return(Inf)  # Return infinite likelihood if invalid parameter values are proposed (to penalize optimizer)
  
  Kmax <- find_Kmax(lambda) # Maximum number of Poisson events to consider in the summation (truncate the infinite Poisson sum for computational feasibility)
  
  # Compute the likelihood for each observation in the data
  likelihoods <- sapply(data, function(x) {
    
    if (x == 0) {
      prob <- dpois(0, lambda)  # Special case: if the observed sum is 0, assume it came from 0 events (k=0)
    } else {
      k_vals <- 1:Kmax  # Consider k = 1 to k_max
      poisson_probs <- dpois(k_vals, lambda)  # Probability of k events occurring (Poisson)
      normal_probs <- dnorm(x, mean = k_vals * mu, sd = sqrt(k_vals * sigma^2))  # Probability of observing x given k normal components
      prob <-  sum(poisson_probs * normal_probs)  # Marginal probability of x via convolution (weighted sum over possible k)
    }
    
    return(prob)  # Return the marginal probability for each observation
  })
  
  return(-sum(log(likelihoods)))  # Return the total negative log-likelihood to be minimized (MLE objective)
}

# Maximum Likelihood Estimation function for the Compound Poisson-Normal model
# Goal: Minimize a nonlinear function f(theta) where theta is a vector of parameters.
# BFGS is gradient-based, meaning it uses first derivatives (the gradient) of the function to move toward a minimum.
# Unlike Newton's method (which uses second derivatives â€” the Hessian), BFGS approximates the Hessian iteratively using only gradients. 

cpn_mle <- function(data) {
  init_vals <- c(1, mean(data), sd(data))  # Provide starting values based on simple moment-based estimates
  mle_result <- optim(
    par = init_vals,  # Initial guesses for lambda, mu, sigma
    fn = cpn_neg_log_likelihood,  # Objective function to minimize
    data = data,  # Observed data
    method = "Nelder-Mead"  # Optimization algorithm
  )
  # Return results as a list
  return(list(
    logLik = -mle_result$value,
    parameters = mle_result$par
  ))
}

# --- Alternative Model: different lambdas, shared mu, sigma ---
neg_log_lik_alt <- function(params, data, group) {
  lambda1 <- params[1]
  lambda2 <- params[2]
  mu <- params[3]
  sigma <- params[4]
  

  
  likelihoods <- mapply(function(x, g) {
    
    lambda <- if (g == 1) lambda1 else lambda2
    
    if (lambda <= 0 || sigma <= 0) return(Inf)
    
    Kmax <- find_Kmax(lambda) # Maximum number of Poisson events to consider in the summation (truncate the infinite Poisson sum for computational feasibility)
    
    #print(Kmax)
    
    if (x == 0) {
      prob <- dpois(0, lambda)
    } else {
      k_vals <- 1:Kmax
      poisson_probs <- dpois(k_vals, lambda)
      normal_probs <- dnorm(x, mean = k_vals * mu, sd = sqrt(k_vals * sigma^2))
      prob <- sum(poisson_probs * normal_probs)
    }
    
    return(prob)
    
  }, x = data, g = group)

  return(-sum(log(likelihoods))) 
}


cpn_alternative_model <- function(data, group) {

  # Initialize parameters: lambda1, lambda2, mu, sigma
  init_alt <- c(1, 1, mean(data), sd(data))
  
  # Fit the model using optim
  fit_alt <- optim(
    par = init_alt,  # Initial guesses for lambda1,lambda2, mu, sigma
    fn = neg_log_lik_alt, # Objective function to minimize
    data = ps_data_pooled,  # Observed data
    group = group,  # Observed data - categories
    method = "Nelder-Mead"
  )
  
  # Return results as a list
  return(list(
    logLik = -fit_alt$value,
    parameters = fit_alt$par
  ))
}


mean_diff_ci_cpn <- function(fit_alt, group, alpha = 0.05) {
  # Extract estimated parameters
  lambda1_hat <- fit_alt$parameters[1]
  lambda2_hat <- fit_alt$parameters[2]
  mu_hat <- fit_alt$parameters[3]
  sigma_hat <- fit_alt$parameters[4]
  
  # Compute group sizes
  n1 <- sum(group == 1)
  n2 <- sum(group == 2)
  
  # Compute means
  mean1_hat <- lambda1_hat * mu_hat
  mean2_hat <- lambda2_hat * mu_hat
  mean_diff <- mean1_hat - mean2_hat
  
  # Compute variances for each group
  var1_hat <- lambda1_hat * (mu_hat^2 + sigma_hat^2)
  var2_hat <- lambda2_hat * (mu_hat^2 + sigma_hat^2)
  
  # Pooled standard deviation
  pooled_sd <- sqrt(((n1 - 1) * var1_hat + (n2 - 1) * var2_hat) / (n1 + n2 - 2))
  
  # Standard error of the mean difference
  se_diff <- pooled_sd * sqrt(1 / n1 + 1 / n2)
  
  # Confidence interval
  z_value <- qnorm(1 - alpha / 2)
  ci_lower <- mean_diff - z_value * se_diff
  ci_upper <- mean_diff + z_value * se_diff
  
  # Return as a list
  return(list(
    mean_diff = mean_diff,
    ci_lower = ci_lower,
    ci_upper = ci_upper,
    se = se_diff,
    pooled_sd = pooled_sd
  ))
}

####################
# Import datasets  #
####################

adps <- read_xpt("/data/ta799-007-fa/cdisc/11_adam_xpt/adps.xpt")

# Subsetting the data based on the conditions in the SAS code
adps_filtered <- adps[adps$PARAMCD == "WKPSVOL" & 
                        adps$FASFL == "Y" & 
                        adps$ANL03FL == "Y", ]


nVisit24 = length(na.omit(unique(adps$AVISITN[adps$AVISITN <= 24 & adps$AVISITN > 0])))
nVisit24

adpssample <-  adps_filtered[!is.na(adps_filtered$CHG) &
                               adps_filtered$AVISITN== 24, ]


# Calculate the mean and standard deviation by treatment (trt01P)
summary_stats <- adpssample %>%
  group_by(TRT01P) %>%
  summarise(
    Mean = mean(CHG, na.rm = TRUE),
    SE = sd(CHG, na.rm = TRUE) / sqrt(n())
  )

# View the summary statistics
print(summary_stats)


ps_data1 <-  adpssample$CHG[adpssample$TRT01P=="PLACEBO"] # Generate 1000 observations from a Compound Poisson-Normal distribution
ps_data2 <- adpssample$CHG[adpssample$TRT01P=="APRAGLUTIDE"]  # Generate 1000 observations from a Compound Poisson-Normal distribution


mle_estimates1 <- cpn_mle(ps_data1)$parameters  # Estimate lambda, mu, and sigma using MLE

cpn_mle(ps_data1)



cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE


cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)


# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))

# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")

fit_alt <- cpn_alternative_model(ps_data_pooled, group)
result <- mean_diff_ci_cpn(fit_alt, group)
cat("Mean Difference:", result$mean_diff, "\n")
cat("95% CI: [", result$ci_lower, ",", result$ci_upper, "]\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)



#####################
# Plot the CPN data #
#####################

combined_data <- data.frame(
  value = c(ps_data1, ps_data2),  # Response variable (Poisson-distributed counts)
  dataset = rep(c("Dataset1", "Dataset2"), c(length(ps_data1), length(ps_data2)))  # Grouping variable
)


# Combine both datasets into one for plotting
summary_data <- data.frame(
  dataset = c("Dataset1", "Dataset2"),
  mean = c(mle_estimates1[1] * mle_estimates1[2], mle_estimates2[1] * mle_estimates2[2])
)


ggplot(combined_data, aes(x = dataset, y = value, color = dataset)) +
  geom_point(position = position_jitter(width = 0.2, height = 0), size = 2, alpha = 0.6) +  # Jitter points
  geom_point(data = summary_data, aes(x = dataset, y = mean), color = "black", size = 5, shape = 18) +  # Mean points
  #geom_pointrange(data = summary_data, aes(x = dataset, y = mean, ymin = lower, ymax = upper), color = "black", size = 0.5)  +
  labs(
    title = "CPN Data",
    x = "Dataset",
    y = "Value"
  ) +
  scale_color_manual(values = c("blue", "red")) +
  theme_minimal()

rm(ps_data1, ps_data2, ps_data_pooled, logL_alt, logL_null)

#########################
# Only CIC  at Week 24  #
#########################

ps_data1 <-  adpssample$CHG[adpssample$TRT01P=="PLACEBO" & adpssample$PTTYPE=="CIC"] # Generate 1000 observations from a Compound Poisson-Normal distribution
ps_data2 <- adpssample$CHG[adpssample$TRT01P=="APRAGLUTIDE" & adpssample$PTTYPE=="CIC"]  # Generate 1000 observations from a Compound Poisson-Normal distribution


mle_estimates1 <- cpn_mle(ps_data1)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)


# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))



# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)

rm(ps_data1, ps_data2, ps_data_pooled, logL_alt, logL_null)

###########################
# Only STOMA  at Week 24  #
#########################@@

ps_data1 <-  adpssample$CHG[adpssample$TRT01P=="PLACEBO" & adpssample$PTTYPE=="STOMA"] # Generate 1000 observations from a Compound Poisson-Normal distribution
ps_data2 <- adpssample$CHG[adpssample$TRT01P=="APRAGLUTIDE" & adpssample$PTTYPE=="STOMA"]  # Generate 1000 observations from a Compound Poisson-Normal distribution


mle_estimates1 <- cpn_mle(ps_data1)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)

# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))



# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)

rm(ps_data1, ps_data2, ps_data_pooled, logL_alt, logL_null)

#########################
# Only CIC  at Week 48  #
#########################

nVisit48 = length(na.omit(unique(adps$AVISITN[adps$AVISITN <= 48 & adps$AVISITN > 0])))

nVisit48

adps_filtered_CIC48 <-  adps[adps$PARAMCD == "WKPSVOL" & 
                               adps$FASFL == "Y" & 
                               adps$ANL03FL == "Y" & 
                               adps$PTTYPE =="CIC" &
                               !is.na(adps$CHG) &
                               adps$AVISITN== 48, ]

# Calculate the mean and standard deviation by treatment (trt01P)
summary_stats <- adps_filtered_CIC48%>%
  group_by(TRT01P) %>%
  summarise(
    Mean = mean(CHG, na.rm = TRUE),
    SE = sd(CHG, na.rm = TRUE) / sqrt(n()),
    n = n()
  )

# View the summary statistics
print(summary_stats)



ps_data1 <- adps_filtered_CIC48$CHG[adps_filtered_CIC48$TRT01P=="PLACEBO" ]
ps_data2 <- adps_filtered_CIC48$CHG[adps_filtered_CIC48$TRT01P=="APRAGLUTIDE"] 


mle_estimates1 <- cpn_mle(ps_data1)$parameters 

cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)


# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))

# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)

rm(ps_data1, ps_data2, ps_data_pooled, logL_alt, logL_null)
######################################
# Comparing CIC short remnant colon  at week 48 #
######################################

adps_filtered_CIC48S <-  adps[adps$PARAMCD == "WKPSVOL" & 
                               adps$FASFL == "Y" & 
                               adps$ANL03FL == "Y" & 
                               adps$PTTYPE =="CIC" &
                               !is.na(adps$CHG) &
                               adps$AVISITN == 48 & 
                               adps$RMCLGR1 != ">= 57%" , ]


# Calculate the mean and standard deviation by treatment (trt01P)
summary_stats <- adps_filtered_CIC48S%>%
  group_by(TRT01P) %>%
  summarise(
    Mean = mean(CHG, na.rm = TRUE),
    SE = sd(CHG, na.rm = TRUE) / sqrt(n()),
    n = n()
  )

# View the summary statistics
print(summary_stats)



ps_data1 <- adps_filtered_CIC48S$CHG[adps_filtered_CIC48S$TRT01P=="PLACEBO" ]
ps_data2 <- adps_filtered_CIC48S$CHG[adps_filtered_CIC48S$TRT01P=="APRAGLUTIDE"] 


mle_estimates1 <- cpn_mle(ps_data1)$parameters 

cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)


# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))

# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)

rm(ps_data1, ps_data2, ps_data_pooled, logL_alt, logL_null)


################################################
# Comparing CIC long remnant colon  at week 48 #
################################################

adps_filtered_CIC48L <-  adps[adps$PARAMCD == "WKPSVOL" & 
                                adps$FASFL == "Y" & 
                                adps$ANL03FL == "Y" & 
                                adps$PTTYPE =="CIC" &
                                !is.na(adps$CHG) &
                                adps$AVISITN == 48 & 
                                adps$RMCLGR1 == ">= 57%" , ]


# Calculate the mean and standard deviation by treatment (trt01P)
summary_stats <- adps_filtered_CIC48L%>%
  group_by(TRT01P) %>%
  summarise(
    Mean = mean(CHG, na.rm = TRUE),
    SE = sd(CHG, na.rm = TRUE) / sqrt(n()),
    n = n()
  )

# View the summary statistics
print(summary_stats)



ps_data1 <- adps_filtered_CIC48L$CHG[adps_filtered_CIC48L$TRT01P=="PLACEBO" ]
ps_data2 <- adps_filtered_CIC48L$CHG[adps_filtered_CIC48L$TRT01P=="APRAGLUTIDE"] 


mle_estimates1 <- cpn_mle(ps_data1)$parameters 

cat("Estimated lambda:", mle_estimates1[1], "\n")
cat("Estimated mu:", mle_estimates1[2], "\n")
cat("Estimated sigma:", mle_estimates1[3], "\n")
cat("Estimated mean:", mle_estimates1[1] * mle_estimates1[2], "\n")

mean(ps_data1)

mle_estimates2 <- cpn_mle(ps_data2)$parameters  # Estimate lambda, mu, and sigma using MLE

cat("Estimated lambda:", mle_estimates2[1], "\n")
cat("Estimated mu:", mle_estimates2[2], "\n")
cat("Estimated sigma:", mle_estimates2[3], "\n")
cat("Estimated mean:", mle_estimates2[1] * mle_estimates2[2], "\n")

mean(ps_data2)


# Combine data and group labels
ps_data_pooled <- c(ps_data1, ps_data2)
group <- factor(c(rep(1,length(ps_data1)),rep(2,length(ps_data2)) ))

# --- Null Model: shared lambda, mu and sigma ---
logL_null <- cpn_mle(ps_data_pooled)$logLik

# --- Alternative Model: different lambdas, shared mu and sigma ---
logL_alt <- cpn_alternative_model(ps_data_pooled, group)$logLik 

# --- LRT ---
lrt_stat <- 2 * (logL_alt - logL_null)
p_value <- pchisq(lrt_stat, df = 1, lower.tail = FALSE)

# Output
cat("Log-likelihood (Null):", logL_null, "\n")
cat("Log-likelihood (Alt):", logL_alt, "\n")
cat("LRT Statistic:", lrt_stat, "\n")
cat("p-value:", p_value, "\n")


# Comparibg to t-test
# T-test expected to show a higher p-value
t.test(ps_data1, ps_data2)
